# Phase 2: Multi-Tree Scalability (The "Cashier Lane" Architecture)

## ğŸš§ Current Bottleneck

The MVP operates with a **Single Merkle Tree** strategy to ensure deterministic Asset ID prediction.

- **Constraint**: `concurrency: 1`
- **Throughput**: ~4 mints/minute (limited by Solana block finalization and serial processing)
- **Risk**: If 100 users upload simultaneously, the queue wait time increases linearly.

## ğŸš€ Phase 2 Solution: Parallel Processing with Multiple Trees

We can scale linearly by adding more Merkle Trees, analogous to opening more "cashier lanes" at a supermarket.

### Architecture Design

1. **Tree Pool**: Deploy N Merkle Trees (e.g., 50 trees).
2. **Job Routing**:
   - When a job enters the Redis Queue, assign it to a specific `TreeID` (Round-Robin or Random).
   - Or, run multiple Worker instances, each subscribed to a specific `TreeID`.
3. **Parallel Execution**:
   - Tree #1 processes Job A.
   - Tree #2 processes Job B.
   - ...
   - Tree #50 processes Job Z.

### Impact
- **Throughput**: 50x increase (with 50 trees).
- **Cost**: Only the one-time cost of creating trees (~$10 per tree). No increase in per-mint cost.
- **Verification Logic**: Our "Search & Match" verification logic is already tree-agnostic. It verifies the mutual link between Arweave and *any* valid cNFT, regardless of which tree it belongs to.

### Database Schema Changes
No major schema changes required. The `merkle_tree_address` can be dynamically selected from a configuration pool instead of an environment variable.

---

# è¤‡æ•°Merkle Treeæˆ¦ç•¥ã®å®Ÿç¾å¯èƒ½æ€§åˆ†æ

## èƒŒæ™¯

ç¾åœ¨ã®å®Ÿè£…ã§ã¯ã€å˜ä¸€Merkle Treeã§`concurrency: 1`ã®ã‚­ãƒ¥ãƒ¼å‡¦ç†ã‚’è¡Œã£ã¦ã„ã‚‹ã€‚10äººãŒåŒæ™‚ã«Uploadã—ãŸå ´åˆã€æœ€å¤§5åˆ†ï¼ˆ10 Ã— 30ç§’ï¼‰ã®å¾…ã¡æ™‚é–“ãŒç™ºç”Ÿã™ã‚‹ã€‚

## ææ¡ˆ

100å€‹ã®Merkle Treeã‚’ãƒ©ãƒ³ãƒ€ãƒ æŒ¯ã‚Šåˆ†ã‘ã§ä¸¦åˆ—å‡¦ç†ã—ã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’100å€ã«å‘ä¸Šã•ã›ã‚‹ã€‚

## åˆæœŸã®æ‡¸å¿µç‚¹

### 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã®ç«¶åˆ
**æ‡¸å¿µ**: `original_hash TEXT NOT NULL UNIQUE` åˆ¶ç´„ã«ã‚ˆã‚Šã€ç•°ãªã‚‹Treeã§åŒã˜ãƒãƒƒã‚·ãƒ¥ã‚’Mintã§ããªã„ã®ã§ã¯ï¼Ÿ

**çµè«–**: å•é¡Œãªã—ã€‚ã©ã®Treeã§Mintã•ã‚Œã‚ˆã†ãŒã€`original_hash`ãŒåŒã˜ = åŒä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®è¨¼æ˜ã€‚RootLensã¨ã—ã¦ã€ŒåŒã˜ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä¸€åº¦ã ã‘è¨¼æ˜ã™ã‚‹ã€ã¨ã„ã†ãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«ã€‚UNIQUEåˆ¶ç´„ã¯æ„å›³ã•ã‚ŒãŸå‹•ä½œã€‚

### 2. ä¸¦åˆ—å‡¦ç†æ™‚ã®ç«¶åˆçŠ¶æ…‹ï¼ˆRace Conditionï¼‰
**æ‡¸å¿µ**: åŒã˜`original_hash`ã®JobãŒç•°ãªã‚‹Treeã§åŒæ™‚å‡¦ç†ã•ã‚Œã€Arweave/cNFTã®äºŒé‡ä½œæˆãŒç™ºç”Ÿã™ã‚‹ã®ã§ã¯ï¼Ÿ

**çµè«–**: å•é¡Œãªã—ã€‚è‡ªç„¶ãªè§£æ±ºãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒå­˜åœ¨ã™ã‚‹ã€‚
- Job1, Job2ãŒåŒã˜`original_hash`ã§ä¸¦åˆ—å‡¦ç†
- ä¸¡æ–¹ãŒArweaveã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ»cNFT Mintã‚’å®Œäº†
- Supabase INSERTæ™‚ã«**ç‰‡æ–¹ãŒUNIQUEåˆ¶ç´„é•åã§å¤±æ•—**
- **å…ˆã«å®Œäº†ã—ãŸæ–¹ãŒæ­£å½“ãªè¨¼æ˜ã¨ã—ã¦è¨˜éŒ²ã•ã‚Œã‚‹**ï¼ˆã‚­ãƒ¥ãƒ¼ã®é †åºä¿è¨¼ï¼‰

Arweave/Solanaã«å†—é•·ãƒ‡ãƒ¼ã‚¿ãŒæ®‹ã‚‹ãŒã€Supabaseã«è¨˜éŒ²ã•ã‚Œã‚‹ã®ã¯1ã¤ã®ã¿ã§ã‚ã‚Šã€ã‚·ã‚¹ãƒ†ãƒ ã¨ã—ã¦æ•´åˆæ€§ãŒä¿ãŸã‚Œã‚‹ã€‚

## æœ€çµ‚çµè«–

**100å€‹ã®Merkle Treeãƒ©ãƒ³ãƒ€ãƒ æŒ¯ã‚Šåˆ†ã‘ã¯å®Ÿç¾å¯èƒ½ã€‚è¿½åŠ ã®ãƒ­ãƒƒã‚¯æ©Ÿæ§‹ã¯ä¸è¦ã€‚**

## å®Ÿè£…è¦ä»¶

### 1. Treeé¸æŠãƒ­ã‚¸ãƒƒã‚¯
```typescript
function selectRandomTree(): string {
  const trees = process.env.MERKLE_TREE_ADDRESSES!.split(',');
  return trees[Math.floor(Math.random() * trees.length)];
}
```

### 2. é–¢æ•°ã‚·ã‚°ãƒãƒãƒ£å¤‰æ›´
- `predictNextAssetId(treeAddress: string)`
- `mintCNFT(data, treeAddress: string)`

### 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒ
```sql
ALTER TABLE media_proofs
  ADD COLUMN merkle_tree_address TEXT;
```

### 4. Workerè¨­å®š
```typescript
const worker = new Worker('rootlens-mint-queue', async (job) => {
  const selectedTree = selectRandomTree();
  return processMint(job.data, selectedTree, job.updateProgress);
}, {
  concurrency: 100,
});
```

### 5. ç’°å¢ƒå¤‰æ•°
```env
MERKLE_TREE_ADDRESSES=Tree1,Tree2,...,Tree100
```

## æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ

- ä¸¦åˆ—åº¦: 1 â†’ 100ï¼ˆ100å€ï¼‰
- 10äººåŒæ™‚Uploadæ™‚ã®å¾…ã¡æ™‚é–“: æœ€å¤§5åˆ† â†’ æœ€å¤§30ç§’
- ã‚·ã‚¹ãƒ†ãƒ æ•´åˆæ€§: ç¶­æŒï¼ˆUNIQUEåˆ¶ç´„ã«ã‚ˆã‚‹è‡ªç„¶ãªé‡è¤‡æ’é™¤ï¼‰